{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanxh/anaconda3/envs/torch112/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import sys\n",
    "import scanpy as sc\n",
    "\n",
    "import scglue\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/yanxh/gitrepo/multi-omics-matching/neurips2021_multimodal_topmethods-main'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(root_dir, 'output/datasets/match_modality/openproblems_bmmc_multiome_phase2_rna/openproblems_bmmc_multiome_phase2_rna.censor_dataset.output_')\n",
    "\n",
    "par = {\n",
    "    'input_train_mod1': f'{dataset_path}train_mod1.h5ad',\n",
    "    'input_train_mod2': f'{dataset_path}train_mod2.h5ad',\n",
    "    'input_train_sol': f'{dataset_path}train_sol.h5ad',\n",
    "    'output_pretrain': os.path.join(root_dir, 'output/pretrain/clue/openproblems_bmmc_multiome_phase2_rna.clue_train.output_pretrain/')\n",
    "}\n",
    "\n",
    "meta = { 'resources_dir': os.path.join(root_dir, 'src/match_modality/methods/clue/resources') }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(meta['resources_dir'])\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading `h5ad` files...\n"
     ]
    }
   ],
   "source": [
    "print('Reading `h5ad` files...')\n",
    "input_train_mod1 = ad.read_h5ad(par['input_train_mod1'])\n",
    "input_train_mod2 = ad.read_h5ad(par['input_train_mod2'])\n",
    "input_train_sol = ad.read_h5ad(par['input_train_sol'])\n",
    "\n",
    "input_train_mod1.X = input_train_mod1.X.astype(np.float32)\n",
    "input_train_mod2.X = input_train_mod2.X.astype(np.float32)\n",
    "input_train_mod1.layers[\"counts\"] = input_train_mod1.layers[\"counts\"].astype(np.float32)\n",
    "input_train_mod2.layers[\"counts\"] = input_train_mod2.layers[\"counts\"].astype(np.float32)\n",
    "\n",
    "mod1_feature_type = set(input_train_mod1.var[\"feature_types\"])\n",
    "mod2_feature_type = set(input_train_mod2.var[\"feature_types\"])\n",
    "assert len(mod1_feature_type) == len(mod2_feature_type) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AnnData object with n_obs × n_vars = 42492 × 13431\n",
       "     obs: 'batch', 'size_factors'\n",
       "     var: 'gene_ids', 'feature_types'\n",
       "     uns: 'dataset_id', 'organism'\n",
       "     layers: 'counts',\n",
       " AnnData object with n_obs × n_vars = 42492 × 116490\n",
       "     obs: 'batch'\n",
       "     var: 'feature_types'\n",
       "     uns: 'dataset_id', 'gene_activity_var_names', 'organism'\n",
       "     obsm: 'gene_activity'\n",
       "     layers: 'counts')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train_mod1, input_train_mod2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GEX', 'ATAC')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1_feature_type = mod1_feature_type.pop()\n",
    "mod2_feature_type = mod2_feature_type.pop()\n",
    "\n",
    "mod1_feature_type, mod2_feature_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if {mod1_feature_type, mod2_feature_type} == {\"GEX\", \"ATAC\"}:\n",
    "    omics = \"multiome\"\n",
    "elif {mod1_feature_type, mod2_feature_type} == {\"GEX\", \"ADT\"}:\n",
    "    omics = \"cite\"\n",
    "else:\n",
    "    raise RuntimeError(\"Unrecognized modality!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if omics == \"cite\":\n",
    "    n_genes = 5000\n",
    "    latent_dim = 20\n",
    "    x2u_h_depth = 2\n",
    "    x2u_h_dim = 512\n",
    "    u2x_h_depth = 1\n",
    "    u2x_h_dim = 128\n",
    "    du_h_depth = 2\n",
    "    du_h_dim = 128\n",
    "    dropout = 0.2\n",
    "    lam_data = 1.0\n",
    "    lam_kl = 1.0\n",
    "    lam_align = 2.0\n",
    "    lam_cross = 2.0\n",
    "    lam_cos = 1.0\n",
    "    normalize_u = True\n",
    "    random_seed = 5\n",
    "elif omics == \"multiome\":\n",
    "    n_genes = 10000\n",
    "    latent_dim = 50\n",
    "    x2u_h_depth = 2\n",
    "    x2u_h_dim = 512\n",
    "    u2x_h_depth = 1\n",
    "    u2x_h_dim = 256\n",
    "    du_h_depth = 1\n",
    "    du_h_dim = 256\n",
    "    dropout = 0.2\n",
    "    lam_data = 1.0\n",
    "    lam_kl = 0.3\n",
    "    lam_align = 0.02\n",
    "    lam_cross = 1.0\n",
    "    lam_cos = 0.02\n",
    "    normalize_u = True\n",
    "    random_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(par['output_pretrain'], exist_ok=True)\n",
    "with open(os.path.join(par['output_pretrain'], \"hyperparams.yaml\"), \"w\") as f:\n",
    "    yaml.dump({\n",
    "        \"n_genes\": n_genes,\n",
    "        \"latent_dim\": latent_dim,\n",
    "        \"x2u_h_depth\": x2u_h_depth,\n",
    "        \"x2u_h_dim\": x2u_h_dim,\n",
    "        \"u2x_h_depth\": u2x_h_depth,\n",
    "        \"u2x_h_dim\": u2x_h_dim,\n",
    "        \"du_h_depth\": du_h_depth,\n",
    "        \"du_h_dim\": du_h_dim,\n",
    "        \"dropout\": dropout,\n",
    "        \"lam_data\": lam_data,\n",
    "        \"lam_kl\": lam_kl,\n",
    "        \"lam_align\": lam_align,\n",
    "        \"lam_cross\": lam_cross,\n",
    "        \"lam_cos\": lam_cos,\n",
    "        \"normalize_u\": normalize_u,\n",
    "        \"random_seed\": random_seed\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unscrambling training cells...\n"
     ]
    }
   ],
   "source": [
    "print(\"Unscrambling training cells...\")\n",
    "ord = input_train_sol.X.tocsr().indices\n",
    "if \"pairing_ix\" in input_train_sol.uns:\n",
    "    assert np.all(ord == np.argsort(input_train_sol.uns[\"pairing_ix\"]))\n",
    "input_train_mod2 = input_train_mod2[ord, :].copy()\n",
    "input_train_mod2.obs_names = input_train_mod1.obs_names\n",
    "input_train_mod1.obs[\"uid\"] = [f\"train-{i}\" for i in range(input_train_mod1.shape[0])]\n",
    "input_train_mod2.obs[\"uid\"] = [f\"train-{i}\" for i in range(input_train_mod2.shape[0])]\n",
    "assert np.all(input_train_mod1.obs[\"batch\"] == input_train_mod2.obs[\"batch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GEX'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1_feature_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mod1_feature_type == \"GEX\":\n",
    "    gex = input_train_mod1\n",
    "    other = input_train_mod2\n",
    "else:\n",
    "    gex = input_train_mod2\n",
    "    other = input_train_mod1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing GEX...\n",
      "Preprocessing ATAC...\n"
     ]
    }
   ],
   "source": [
    "print('Preprocessing GEX...')\n",
    "gex_prep = utils.GEXPreprocessing(n_comps=100, n_genes=n_genes, merge_adt=omics == \"cite\", scale=True, clip=True)\n",
    "gex_prep.fit_transform(gex)\n",
    "\n",
    "if omics == \"cite\":\n",
    "    print('Preprocessing ADT...')\n",
    "    other_prep = utils.ADTPreprocessing(n_comps=100, scale=True, clip=True)\n",
    "elif omics == \"multiome\":\n",
    "    print('Preprocessing ATAC...')\n",
    "    other_prep = utils.ATACPreprocessing(n_comps=100)\n",
    "    \n",
    "other_prep.fit_transform(other, X_lsi=np.load('./cache/clue-multiome/atac_X_lsi.npy'))\n",
    "# np.save('./cache/clue-multiome/atac_X_lsi.npy', other.obsm['X_lsi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./cache/clue-multiome/atac_X_lsi.npy', other.obsm['X_lsi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(par['output_pretrain'], \"prep.pickle\"), \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"gex_prep\": gex_prep,\n",
    "        \"other_prep\": other_prep\n",
    "    }, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scglue.models.configure_dataset(\n",
    "    gex, \"NB\", use_highly_variable=True,\n",
    "    use_layer=\"counts\", use_rep=\"X_pca\",\n",
    "    use_batch=\"batch\", use_uid=\"uid\"\n",
    ")\n",
    "scglue.models.configure_dataset(\n",
    "    other, \"NB\", use_highly_variable=True,\n",
    "    use_layer=\"counts\", use_rep=\"X_lsi\",\n",
    "    use_batch=\"batch\", use_uid=\"uid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "[INFO] autodevice: Using GPU 1 as computation device.\n"
     ]
    }
   ],
   "source": [
    "print('Building model...')\n",
    "model = scglue.models.SCCLUEModel(\n",
    "    {\"gex\": gex, \"other\": other},\n",
    "    latent_dim=latent_dim,\n",
    "    x2u_h_depth=x2u_h_depth,\n",
    "    x2u_h_dim=x2u_h_dim,\n",
    "    u2x_h_depth=u2x_h_depth,\n",
    "    u2x_h_dim=u2x_h_dim,\n",
    "    du_h_depth=du_h_depth,\n",
    "    du_h_dim=du_h_dim,\n",
    "    dropout=dropout,\n",
    "    shared_batches=True,\n",
    "    random_seed=random_seed\n",
    ")\n",
    "\n",
    "training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pretrained weight\n",
    "model = scglue.models.load_model(os.path.join(par['output_pretrain'], \"pretrain.dill\"))\n",
    "training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n"
     ]
    }
   ],
   "source": [
    "print('Compiling model...')\n",
    "model.compile(\n",
    "    lam_data=lam_data, lam_kl=lam_kl, lam_align=lam_align,\n",
    "    lam_cross=lam_cross, lam_cos=lam_cos, normalize_u=normalize_u,\n",
    "    domain_weight={\"gex\": 1, \"other\": 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "[INFO] SCCLUEModel: Setting `align_burnin` = 21\n",
      "[INFO] SCCLUEModel: Setting `max_epochs` = 121\n",
      "[INFO] SCCLUEModel: Setting `patience` = 16\n",
      "[INFO] SCCLUEModel: Setting `reduce_lr_patience` = 6\n",
      "[INFO] SCCLUETrainer: Using training directory: \"/tmp/GLUETMPlkt0ojvl\"\n",
      "[INFO] SCCLUETrainer: [Epoch 10] train={'dsc_loss': 0.685, 'gen_loss': 1.313, 'cross_loss': 0.66, 'cos_loss': 0.096, 'x_gex_nll': 0.282, 'x_gex_kl': 0.011, 'x_gex_elbo': 0.285, 'x_other_nll': 0.378, 'x_other_kl': 0.005, 'x_other_elbo': 0.379}, val={'dsc_loss': 0.69, 'gen_loss': 1.301, 'cross_loss': 0.655, 'cos_loss': 0.087, 'x_gex_nll': 0.277, 'x_gex_kl': 0.011, 'x_gex_elbo': 0.28, 'x_other_nll': 0.377, 'x_other_kl': 0.005, 'x_other_elbo': 0.378}, 11.6s elapsed\n",
      "[INFO] SCCLUETrainer: [Epoch 20] train={'dsc_loss': 0.681, 'gen_loss': 1.307, 'cross_loss': 0.657, 'cos_loss': 0.093, 'x_gex_nll': 0.28, 'x_gex_kl': 0.011, 'x_gex_elbo': 0.283, 'x_other_nll': 0.376, 'x_other_kl': 0.005, 'x_other_elbo': 0.378}, val={'dsc_loss': 0.684, 'gen_loss': 1.299, 'cross_loss': 0.654, 'cos_loss': 0.085, 'x_gex_nll': 0.276, 'x_gex_kl': 0.011, 'x_gex_elbo': 0.28, 'x_other_nll': 0.376, 'x_other_kl': 0.005, 'x_other_elbo': 0.377}, 11.8s elapsed\n",
      "[INFO] SCCLUETrainer: [Epoch 30] train={'dsc_loss': 0.682, 'gen_loss': 1.305, 'cross_loss': 0.657, 'cos_loss': 0.093, 'x_gex_nll': 0.279, 'x_gex_kl': 0.012, 'x_gex_elbo': 0.283, 'x_other_nll': 0.376, 'x_other_kl': 0.005, 'x_other_elbo': 0.377}, val={'dsc_loss': 0.686, 'gen_loss': 1.298, 'cross_loss': 0.653, 'cos_loss': 0.085, 'x_gex_nll': 0.276, 'x_gex_kl': 0.012, 'x_gex_elbo': 0.279, 'x_other_nll': 0.376, 'x_other_kl': 0.005, 'x_other_elbo': 0.378}, 11.5s elapsed\n",
      "Epoch 00036: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 00036: reducing learning rate of group 0 to 2.0000e-04.\n",
      "[INFO] SCCLUETrainer: [Epoch 40] train={'dsc_loss': 0.687, 'gen_loss': 1.302, 'cross_loss': 0.655, 'cos_loss': 0.091, 'x_gex_nll': 0.278, 'x_gex_kl': 0.012, 'x_gex_elbo': 0.282, 'x_other_nll': 0.375, 'x_other_kl': 0.005, 'x_other_elbo': 0.377}, val={'dsc_loss': 0.68, 'gen_loss': 1.299, 'cross_loss': 0.654, 'cos_loss': 0.082, 'x_gex_nll': 0.275, 'x_gex_kl': 0.012, 'x_gex_elbo': 0.279, 'x_other_nll': 0.377, 'x_other_kl': 0.005, 'x_other_elbo': 0.379}, 12.2s elapsed\n",
      "[INFO] SCCLUETrainer: [Epoch 50] train={'dsc_loss': 0.687, 'gen_loss': 1.302, 'cross_loss': 0.655, 'cos_loss': 0.092, 'x_gex_nll': 0.278, 'x_gex_kl': 0.012, 'x_gex_elbo': 0.282, 'x_other_nll': 0.375, 'x_other_kl': 0.005, 'x_other_elbo': 0.377}, val={'dsc_loss': 0.678, 'gen_loss': 1.296, 'cross_loss': 0.652, 'cos_loss': 0.084, 'x_gex_nll': 0.275, 'x_gex_kl': 0.012, 'x_gex_elbo': 0.279, 'x_other_nll': 0.376, 'x_other_kl': 0.005, 'x_other_elbo': 0.377}, 11.9s elapsed\n",
      "Epoch 00050: reducing learning rate of group 0 to 2.0000e-05.\n",
      "Epoch 00050: reducing learning rate of group 0 to 2.0000e-05.\n",
      "[INFO] SCCLUETrainer: [Epoch 60] train={'dsc_loss': 0.688, 'gen_loss': 1.302, 'cross_loss': 0.655, 'cos_loss': 0.091, 'x_gex_nll': 0.278, 'x_gex_kl': 0.012, 'x_gex_elbo': 0.282, 'x_other_nll': 0.375, 'x_other_kl': 0.005, 'x_other_elbo': 0.377}, val={'dsc_loss': 0.678, 'gen_loss': 1.298, 'cross_loss': 0.653, 'cos_loss': 0.083, 'x_gex_nll': 0.275, 'x_gex_kl': 0.012, 'x_gex_elbo': 0.279, 'x_other_nll': 0.376, 'x_other_kl': 0.005, 'x_other_elbo': 0.378}, 13.9s elapsed\n",
      "Epoch 00064: reducing learning rate of group 0 to 2.0000e-06.\n",
      "Epoch 00064: reducing learning rate of group 0 to 2.0000e-06.\n",
      "[INFO] SCCLUETrainer: [Epoch 70] train={'dsc_loss': 0.687, 'gen_loss': 1.302, 'cross_loss': 0.655, 'cos_loss': 0.091, 'x_gex_nll': 0.278, 'x_gex_kl': 0.012, 'x_gex_elbo': 0.282, 'x_other_nll': 0.375, 'x_other_kl': 0.005, 'x_other_elbo': 0.377}, val={'dsc_loss': 0.679, 'gen_loss': 1.296, 'cross_loss': 0.653, 'cos_loss': 0.083, 'x_gex_nll': 0.275, 'x_gex_kl': 0.012, 'x_gex_elbo': 0.278, 'x_other_nll': 0.376, 'x_other_kl': 0.005, 'x_other_elbo': 0.378}, 13.4s elapsed\n",
      "Epoch 00071: reducing learning rate of group 0 to 2.0000e-07.\n",
      "Epoch 00071: reducing learning rate of group 0 to 2.0000e-07.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 12:03:34,697 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EarlyStopping: Restoring checkpoint \"57\"...\n",
      "[INFO] EarlyStopping: Restoring checkpoint \"57\"...\n"
     ]
    }
   ],
   "source": [
    "if training:\n",
    "    print('Training model...')\n",
    "    model.fit(\n",
    "        {\"gex\": gex, \"other\": other}\n",
    "    )\n",
    "    model.save(os.path.join(par['output_pretrain'], \"pretrain.dill\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch112",
   "language": "python",
   "name": "torch112"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
