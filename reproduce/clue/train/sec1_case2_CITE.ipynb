{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import sys\n",
    "import scanpy as sc\n",
    "\n",
    "import scglue\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/yanxh/gitrepo/multi-omics-matching/neurips2021_multimodal_topmethods-main'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(root_dir, 'output/datasets/match_modality/openproblems_bmmc_cite_phase2_mod2/openproblems_bmmc_cite_phase2_mod2.censor_dataset.output_')\n",
    "\n",
    "par = {\n",
    "    'input_train_mod1': f'{dataset_path}train_mod1.h5ad',\n",
    "    'input_train_mod2': f'{dataset_path}train_mod2.h5ad',\n",
    "    'input_train_sol': f'{dataset_path}train_sol.h5ad',\n",
    "    'output_pretrain': os.path.join(root_dir, 'output/pretrain/clue/openproblems_bmmc_cite_phase2_mod2.clue_train.output_pretrain/default')\n",
    "}\n",
    "\n",
    "\n",
    "meta = { 'resources_dir': os.path.join(root_dir, 'src/match_modality/methods/clue/resources') }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(meta['resources_dir'])\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading `h5ad` files...\n"
     ]
    }
   ],
   "source": [
    "print('Reading `h5ad` files...')\n",
    "input_train_mod1 = ad.read_h5ad(par['input_train_mod1'])\n",
    "input_train_mod2 = ad.read_h5ad(par['input_train_mod2'])\n",
    "input_train_sol = ad.read_h5ad(par['input_train_sol'])\n",
    "\n",
    "input_train_mod1.X = input_train_mod1.X.astype(np.float32)\n",
    "input_train_mod2.X = input_train_mod2.X.astype(np.float32)\n",
    "input_train_mod1.layers[\"counts\"] = input_train_mod1.layers[\"counts\"].astype(np.float32)\n",
    "input_train_mod2.layers[\"counts\"] = input_train_mod2.layers[\"counts\"].astype(np.float32)\n",
    "\n",
    "mod1_feature_type = set(input_train_mod1.var[\"feature_types\"])\n",
    "mod2_feature_type = set(input_train_mod2.var[\"feature_types\"])\n",
    "assert len(mod1_feature_type) == len(mod2_feature_type) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AnnData object with n_obs × n_vars = 66175 × 134\n",
       "     obs: 'batch'\n",
       "     var: 'feature_types'\n",
       "     uns: 'dataset_id', 'organism'\n",
       "     layers: 'counts',\n",
       " AnnData object with n_obs × n_vars = 66175 × 13953\n",
       "     obs: 'batch', 'size_factors'\n",
       "     var: 'gene_ids', 'feature_types'\n",
       "     uns: 'dataset_id', 'organism'\n",
       "     layers: 'counts')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train_mod1, input_train_mod2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ADT', 'GEX')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1_feature_type = mod1_feature_type.pop()\n",
    "mod2_feature_type = mod2_feature_type.pop()\n",
    "\n",
    "mod1_feature_type, mod2_feature_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if {mod1_feature_type, mod2_feature_type} == {\"GEX\", \"ATAC\"}:\n",
    "    omics = \"multiome\"\n",
    "elif {mod1_feature_type, mod2_feature_type} == {\"GEX\", \"ADT\"}:\n",
    "    omics = \"cite\"\n",
    "else:\n",
    "    raise RuntimeError(\"Unrecognized modality!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if omics == \"cite\":\n",
    "    n_genes = 5000\n",
    "    latent_dim = 20\n",
    "    x2u_h_depth = 2\n",
    "    x2u_h_dim = 512\n",
    "    u2x_h_depth = 1\n",
    "    u2x_h_dim = 128\n",
    "    du_h_depth = 2\n",
    "    du_h_dim = 128\n",
    "    dropout = 0.2\n",
    "    lam_data = 1.0\n",
    "    lam_kl = 1.0\n",
    "    lam_align = 2.0\n",
    "    lam_cross = 2.0\n",
    "    lam_cos = 1.0\n",
    "    normalize_u = True\n",
    "    random_seed = 5\n",
    "elif omics == \"multiome\":\n",
    "    n_genes = 10000\n",
    "    latent_dim = 50\n",
    "    x2u_h_depth = 2\n",
    "    x2u_h_dim = 512\n",
    "    u2x_h_depth = 1\n",
    "    u2x_h_dim = 256\n",
    "    du_h_depth = 1\n",
    "    du_h_dim = 256\n",
    "    dropout = 0.2\n",
    "    lam_data = 1.0\n",
    "    lam_kl = 0.3\n",
    "    lam_align = 0.02\n",
    "    lam_cross = 1.0\n",
    "    lam_cos = 0.02\n",
    "    normalize_u = True\n",
    "    random_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(par['output_pretrain'], exist_ok=True)\n",
    "with open(os.path.join(par['output_pretrain'], \"hyperparams.yaml\"), \"w\") as f:\n",
    "    yaml.dump({\n",
    "        \"n_genes\": n_genes,\n",
    "        \"latent_dim\": latent_dim,\n",
    "        \"x2u_h_depth\": x2u_h_depth,\n",
    "        \"x2u_h_dim\": x2u_h_dim,\n",
    "        \"u2x_h_depth\": u2x_h_depth,\n",
    "        \"u2x_h_dim\": u2x_h_dim,\n",
    "        \"du_h_depth\": du_h_depth,\n",
    "        \"du_h_dim\": du_h_dim,\n",
    "        \"dropout\": dropout,\n",
    "        \"lam_data\": lam_data,\n",
    "        \"lam_kl\": lam_kl,\n",
    "        \"lam_align\": lam_align,\n",
    "        \"lam_cross\": lam_cross,\n",
    "        \"lam_cos\": lam_cos,\n",
    "        \"normalize_u\": normalize_u,\n",
    "        \"random_seed\": random_seed\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unscrambling training cells...\n"
     ]
    }
   ],
   "source": [
    "print(\"Unscrambling training cells...\")\n",
    "ord = input_train_sol.X.tocsr().indices\n",
    "if \"pairing_ix\" in input_train_sol.uns:\n",
    "    assert np.all(ord == np.argsort(input_train_sol.uns[\"pairing_ix\"]))\n",
    "input_train_mod2 = input_train_mod2[ord, :].copy()\n",
    "input_train_mod2.obs_names = input_train_mod1.obs_names\n",
    "input_train_mod1.obs[\"uid\"] = [f\"train-{i}\" for i in range(input_train_mod1.shape[0])]\n",
    "input_train_mod2.obs[\"uid\"] = [f\"train-{i}\" for i in range(input_train_mod2.shape[0])]\n",
    "assert np.all(input_train_mod1.obs[\"batch\"] == input_train_mod2.obs[\"batch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADT'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1_feature_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mod1_feature_type == \"GEX\":\n",
    "    gex = input_train_mod1\n",
    "    other = input_train_mod2\n",
    "else:\n",
    "    gex = input_train_mod2\n",
    "    other = input_train_mod1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing GEX...\n",
      "Preprocessing ADT...\n"
     ]
    }
   ],
   "source": [
    "print('Preprocessing GEX...')\n",
    "gex_prep = utils.GEXPreprocessing(n_comps=100, n_genes=n_genes, merge_adt=omics == \"cite\", scale=True, clip=True)\n",
    "gex_prep.fit_transform(gex)\n",
    "\n",
    "if omics == \"cite\":\n",
    "    print('Preprocessing ADT...')\n",
    "    other_prep = utils.ADTPreprocessing(n_comps=100, scale=True, clip=True)\n",
    "elif omics == \"multiome\":\n",
    "    print('Preprocessing ATAC...')\n",
    "    other_prep = utils.ATACPreprocessing(n_comps=100)\n",
    "    \n",
    "other_prep.fit_transform(other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(par['output_pretrain'], \"prep.pickle\"), \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"gex_prep\": gex_prep,\n",
    "        \"other_prep\": other_prep\n",
    "    }, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scglue.models.configure_dataset(\n",
    "    gex, \"NB\", use_highly_variable=True,\n",
    "    use_layer=\"counts\", use_rep=\"X_pca\",\n",
    "    use_batch=\"batch\", use_uid=\"uid\"\n",
    ")\n",
    "scglue.models.configure_dataset(\n",
    "    other, \"NB\", use_highly_variable=True,\n",
    "    use_layer=\"counts\", use_rep=\"X_pca\",\n",
    "    use_batch=\"batch\", use_uid=\"uid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "[INFO] autodevice: Using GPU 1 as computation device.\n"
     ]
    }
   ],
   "source": [
    "print('Building model...')\n",
    "model = scglue.models.SCCLUEModel(\n",
    "    {\"gex\": gex, \"other\": other},\n",
    "    latent_dim=latent_dim,\n",
    "    x2u_h_depth=x2u_h_depth,\n",
    "    x2u_h_dim=x2u_h_dim,\n",
    "    u2x_h_depth=u2x_h_depth,\n",
    "    u2x_h_dim=u2x_h_dim,\n",
    "    du_h_depth=du_h_depth,\n",
    "    du_h_dim=du_h_dim,\n",
    "    dropout=dropout,\n",
    "    shared_batches=True,\n",
    "    random_seed=random_seed\n",
    ")\n",
    "\n",
    "training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pretrained weight\n",
    "model = scglue.models.load_model(os.path.join(par['output_pretrain'], \"pretrain.dill\"))\n",
    "training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n"
     ]
    }
   ],
   "source": [
    "print('Compiling model...')\n",
    "model.compile(\n",
    "    lam_data=lam_data, lam_kl=lam_kl, lam_align=lam_align,\n",
    "    lam_cross=lam_cross, lam_cos=lam_cos, normalize_u=normalize_u,\n",
    "    domain_weight={\"gex\": 1, \"other\": 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training:\n",
    "    print('Training model...')\n",
    "    model.fit(\n",
    "        {\"gex\": gex, \"other\": other}\n",
    "    )\n",
    "    model.save(os.path.join(par['output_pretrain'], \"pretrain.dill\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch112",
   "language": "python",
   "name": "torch112"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
