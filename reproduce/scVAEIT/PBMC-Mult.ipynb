{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"11\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"8\" # export OPENBLAS_NUM_THREADS=4 \n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"11\" # export MKL_NUM_THREADS=6\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"8\" # export VECLIB_MAXIMUM_THREADS=4\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"11\" # export NUMEXPR_NUM_THREADS=6\n",
    "os.environ[\"NUMBA_CACHE_DIR\"]='/tmp/numba_cache'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy \n",
    "import scipy.io as sio\n",
    "import scipy.sparse as sps\n",
    "import h5py\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# try:\n",
    "#     tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "# except:\n",
    "#     # Invalid device or cannot modify virtual devices once initialized.\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def pearson_mat(X, Y):\n",
    "    X = (X - X.mean(axis=0))\n",
    "    X /= (scipy.linalg.norm(X, axis=0, ord=2) + 1e-12)\n",
    "    Y = (Y - Y.mean(axis=0))\n",
    "    Y /= (scipy.linalg.norm(Y, axis=0, ord=2) + 1e-12)\n",
    "    return (X * Y).sum(axis=0)\n",
    "\n",
    "def eval_pearRmse_AlongGene(X, Y):\n",
    "    pear = pearson_mat(X, Y)\n",
    "    rmse = np.sqrt(np.mean((X-Y)**2, axis=0))\n",
    "    return pear, rmse\n",
    "\n",
    "def eval_spear_AlongGene(X, Y):\n",
    "    spears = []\n",
    "    for gi in range(X.shape[1]):\n",
    "        spears.append(scipy.stats.spearmanr(X[:, gi], Y[:, gi])[0])\n",
    "    return spears\n",
    "\n",
    "def eval_aucRmse_AlongPeak(X, Y):\n",
    "    aucs, rmses = [], []\n",
    "    for pi in range(X.shape[1]):\n",
    "        aucs.append(roc_auc_score(X[:, pi], Y[:, pi]))\n",
    "        rmses.append(\n",
    "            np.sqrt(np.mean((X[:, pi] - Y[:, pi])**2))\n",
    "        )\n",
    "    return aucs, rmses\n",
    "\n",
    "def eval_imputation_flatten(x, y):\n",
    "    pearson_r, pearson_p = scipy.stats.pearsonr(x, y)\n",
    "    print(f\"Found pearson's correlation/p of {pearson_r:.4f}/{pearson_p:.4g}\")\n",
    "    spearman_corr, spearman_p = scipy.stats.spearmanr(x, y)\n",
    "    print(f\"Found spearman's collelation/p of {spearman_corr:.4f}/{spearman_p:.4g}\")\n",
    "    rmse = np.sqrt(np.mean((x - y)**2))\n",
    "    print(f\"Found rmse {rmse:.4f}\")\n",
    "    return pearson_r, spearman_corr, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18534/2863803315.py:16: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  ad_rna = sc.AnnData(X, obs=meta_data.loc[cell_names])\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/home/sda1/yanxh/data/Seurat_demo_data/pbmc_multiome\"\n",
    "\n",
    "# print('Reading `mtx` files...')\n",
    "X = sps.csr_matrix(sio.mmread(join(data_dir, 'rna_mat_norm.mtx')).T)\n",
    "Y = sps.csr_matrix(sio.mmread(join(data_dir, 'atac_mat_norm.mtx')).T)\n",
    "rna_names = pd.read_csv(join(data_dir, 'gene_names.csv'))['x'].to_numpy()\n",
    "atac_names = pd.read_csv(join(data_dir, 'atac_names.csv'))['x'].to_numpy()\n",
    "\n",
    "cell_names = pd.read_csv(join(data_dir, 'cell_names.csv'))['x'].to_numpy()\n",
    "meta_data = pd.read_csv(join(data_dir, 'metadata.csv'), index_col=0)\n",
    "\n",
    "train_idx = pd.read_csv(join(data_dir, 'train_idx.csv'))['0'].to_numpy()\n",
    "test_idx  = pd.read_csv(join(data_dir, 'test_idx.csv'))['0'].to_numpy()\n",
    "\n",
    "# select hvg and hvp\n",
    "ad_rna = sc.AnnData(X, obs=meta_data.loc[cell_names])\n",
    "sc.pp.highly_variable_genes(ad_rna, n_top_genes=5000)\n",
    "hvg_idx = np.where(ad_rna.var.highly_variable)[0]\n",
    "\n",
    "# pick peak startwith chr1-23\n",
    "valid_atac_idx = [\n",
    "    _ for _ in range(len(atac_names)) \n",
    "    if atac_names[_].startswith('chr') and \n",
    "    not atac_names[_].startswith('chrX-') and \n",
    "    not atac_names[_].startswith('chrY-')\n",
    "]\n",
    "valid_atac_names = atac_names[valid_atac_idx]\n",
    "Y = Y[:, valid_atac_idx]\n",
    "\n",
    "hvp_idx = np.argsort(Y.sum(axis=0).A1)[-20000:]\n",
    "hvp_names = valid_atac_names[hvp_idx]\n",
    "sort_idx = np.argsort(hvp_names)\n",
    "sorted_hvp_idx, sorted_hvp_names = hvp_idx[sort_idx], hvp_names[sort_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_X = X[train_idx][:, hvg_idx].A\n",
    "mult_Y = Y[train_idx][:, sorted_hvp_idx].A\n",
    "single_X  = X[test_idx][:, hvg_idx].A\n",
    "single_Y  = Y[test_idx][:, sorted_hvp_idx].A\n",
    "\n",
    "# binarize atac data\n",
    "mult_Y[mult_Y>0.] = 1.\n",
    "single_Y[single_Y>0.] = 1.\n",
    "\n",
    "n_mult, n_rna, n_atac = mult_X.shape[0], single_X.shape[0], single_Y.shape[0]\n",
    "m_rna, m_atac = mult_X.shape[1], mult_Y.shape[1]\n",
    "\n",
    "# Count peaks in each chromosome (assuming they are ordered)\n",
    "chr_set, chr_n_chunk = np.unique([_.split('-')[0] for _ in sorted_hvp_names], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for imputation\n",
    "mult_data = np.hstack([mult_X, mult_Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_input_arr = [m_rna, m_atac]\n",
    "config = {\n",
    "    'dim_input_arr': dim_input_arr,\n",
    "    'dimensions':[256], \n",
    "    'dim_latent':32,\n",
    "    'dim_block': np.append([m_rna], chr_n_chunk), \n",
    "    'dist_block':['NB'] + ['Bernoulli' for _ in chr_n_chunk], \n",
    "    'dim_block_enc':np.array([256] + [16 for _ in chr_n_chunk]),\n",
    "    'dim_block_dec':np.array([256] + [16 for _ in chr_n_chunk]),\n",
    "    'dim_block_embed':np.array([16] + [1 for _ in range(len(chr_n_chunk))])*2,\n",
    "    \n",
    "    'block_names':np.array(['rna'] + ['atac' for _ in range(len(chr_n_chunk))]),\n",
    "    'uni_block_names':np.array(['rna','atac']),\n",
    "    \n",
    "    'beta_kl':1.,\n",
    "    'beta_unobs':2./3.,\n",
    "    'beta_modal':np.array([0.8, 0.2]),  # not very sure\n",
    "    'beta_reverse':0.5,\n",
    "\n",
    "    \"p_feat\" : 0.2,\n",
    "    \"p_modal\" : np.ones(2)/2,\n",
    "    \n",
    "}\n",
    "config = SimpleNamespace(**config)\n",
    "n_samples = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-01 19:02:46.513898: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-01 19:02:46.933649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22306 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:b3:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from scVAEIT.VAEIT import scVAEIT\n",
    "# model = scVAEIT(config, mosaic_data, masks, batch_ids)  # for integration\n",
    "model = scVAEIT(config, mult_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
      "<tensorflow.python.training.tracking.util.CheckpointLoadStatus object at 0x7f93bac8de50>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-01 19:02:51.083789: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    model.train(\n",
    "        valid=False, num_epoch=300, batch_size=512, save_every_epoch=50,\n",
    "        verbose=True, checkpoint_dir='./checkpoint/pbmc-mult-impute'\n",
    "    )\n",
    "\n",
    "# load the model and ensure it is loaded successfully\n",
    "checkpoint = tf.train.Checkpoint(net=model.vae)\n",
    "epoch = 10\n",
    "status = checkpoint.restore('checkpoint/pbmc-mult-impute/ckpt-{}'.format(epoch))\n",
    "\n",
    "# one-step forward?\n",
    "model.vae(tf.zeros((1,np.sum(model.vae.config.dim_input_arr))),\n",
    "          tf.zeros((1,np.sum(model.vae.config.dim_input_arr))),\n",
    "          tf.zeros((1,np.sum(model.batches.shape[1]))), \n",
    "          pre_train=True, L=1, training=False)\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = tf.data.Dataset.from_tensor_slices((\n",
    "    np.hstack([single_X, single_Y]),\n",
    "    model.cat_enc.transform(np.zeros((test_idx.size, 1))).toarray().astype(np.float32),\n",
    "    np.zeros(test_idx.size).astype(np.int32)\n",
    ")).batch(512).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "mask_rna = np.zeros((1, m_rna+m_atac), dtype=np.float32)\n",
    "mask_rna[:,:m_rna] = -1.\n",
    "recon = model.vae.get_recon(dataset_test, mask_rna)\n",
    "X_hat = recon[:, :m_rna]\n",
    "\n",
    "mask_atac = np.zeros((1, m_rna+m_atac), dtype=np.float32)\n",
    "mask_atac[:, m_rna:] = -1.\n",
    "recon = model.vae.get_recon(dataset_test, mask_atac)\n",
    "Y_hat = recon[:, m_rna:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7739375580477281, 0.6450076955902503)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch2: rna->atac\n",
    "x, y = single_Y, Y_hat\n",
    "\n",
    "auc = roc_auc_score(x.flatten(), y.flatten())\n",
    "# rmse = np.sqrt(((x.flatten()-y.flatten())**2).mean())\n",
    "\n",
    "auc_along_peak, rmse_along_peak = eval_aucRmse_AlongPeak(x, y)\n",
    "auc, np.mean(auc_along_peak) # np.mean(rmse_along_peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pearson's correlation/p of 0.7171/0\n",
      "Found spearman's collelation/p of 0.3409/0\n",
      "Found rmse 0.2935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanxh/anaconda3/envs/tf2-py38/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4878: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.14195727723678903, nan)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch3: atac->rna\n",
    "pear1, spear1, rmse = eval_imputation_flatten(single_X.flatten(), X_hat.flatten())\n",
    "pear_along_gene, rmse_along_gene = eval_pearRmse_AlongGene(single_X, X_hat)\n",
    "spear_along_gene = eval_spear_AlongGene(single_X, X_hat)\n",
    "\n",
    "np.mean(pear_along_gene), np.mean(spear_along_gene)#, np.mean(rmse_along_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/home/yanxh/gitrepo/multi-omics-matching/Visualization/outputs/imputation'\n",
    "\n",
    "gene_metcs = np.vstack([pear_along_gene, spear_along_gene]).T\n",
    "_df1 = pd.DataFrame(gene_metcs, index=rna_names[hvg_idx], columns=['pear', 'spear'])\n",
    "_df1.to_csv(join(save_dir, 'scVAEIT_pbmc-mult_along_gene.csv'))\n",
    "\n",
    "peak_metcs = auc_along_peak\n",
    "_df2 = pd.DataFrame(peak_metcs, index=sorted_hvp_names, columns=['auc'])\n",
    "_df2.to_csv(join(save_dir, 'scVAEIT_pbmc-mult_along_peak.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./checkpoint/pbmc-mult-impute/X_test_imputed.npy', X_hat)\n",
    "np.save('./checkpoint/pbmc-mult-impute/Y_test_imputed.npy', Y_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-py38",
   "language": "python",
   "name": "tf2-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
