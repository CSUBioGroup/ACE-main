{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanxh/anaconda3/envs/torch112/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import sys\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sps\n",
    "import scipy.io as sio\n",
    "\n",
    "import scglue\n",
    "import seaborn as sns\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the data directory\n",
    "root_dir = '/home/yanxh/gitrepo/multi-omics-matching/neurips2021_multimodal_topmethods-main'\n",
    "data_dir = \"/home/yanxh/data/Seurat_demo_data/bm_cite\"\n",
    "\n",
    "par = {}\n",
    "par['output_pretrain'] = os.path.join(\n",
    "    root_dir, \n",
    "    'output/pretrain/clue/bm_cite_donorSplit.clue_train.output_pretrain/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading `mtx` files...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((30672, 17009), (30672, 25), 14468, 16204)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Reading `mtx` files...')\n",
    "rna_count_mat = sps.csr_matrix(sio.mmread(join(data_dir, 'rna_mat_count.mtx')).T)\n",
    "adt_count_mat = sps.csr_matrix(sio.mmread(join(data_dir, 'adt_mat_count.mtx')).T)\n",
    "\n",
    "rna_names = pd.read_csv(join(data_dir, 'gene_names.csv'))['x'].to_numpy()\n",
    "adt_names = pd.read_csv(join(data_dir, 'adt_names.csv'))['x'].to_numpy()\n",
    "\n",
    "cell_names = pd.read_csv(join(data_dir, 'cell_names.csv'))['x'].to_numpy()\n",
    "meta_data = pd.read_csv(join(data_dir, 'metadata.csv'), index_col=0)\n",
    "meta_data['batch'] = meta_data.donor.to_numpy()\n",
    "\n",
    "train_idx = np.where((meta_data.batch=='batch1').to_numpy())[0]\n",
    "test_idx  = np.where((meta_data.batch=='batch2').to_numpy())[0]\n",
    "\n",
    "rna_count_mat.shape, adt_count_mat.shape, train_idx.size, test_idx.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(root_dir, 'src/match_modality/methods/clue/resources'))\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading `h5ad` files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30515/1341607515.py:2: FutureWarning: X.dtype being converted to np.float32 from int64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  input_train_mod1 = sc.AnnData(sps.csr_matrix(rna_count_mat[train_idx]), obs=meta_data.iloc[train_idx])\n",
      "/tmp/ipykernel_30515/1341607515.py:3: FutureWarning: X.dtype being converted to np.float32 from int64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  input_train_mod2 = sc.AnnData(sps.csr_matrix(adt_count_mat[train_idx]), obs=meta_data.iloc[train_idx])\n"
     ]
    }
   ],
   "source": [
    "print('Reading `h5ad` files...')\n",
    "input_train_mod1 = sc.AnnData(sps.csr_matrix(rna_count_mat[train_idx]), obs=meta_data.iloc[train_idx])\n",
    "input_train_mod2 = sc.AnnData(sps.csr_matrix(adt_count_mat[train_idx]), obs=meta_data.iloc[train_idx])\n",
    "input_train_mod1.var_names = rna_names\n",
    "input_train_mod2.var_names = adt_names\n",
    "\n",
    "input_train_mod1.layers[\"counts\"] = input_train_mod1.X.astype(np.float32)\n",
    "input_train_mod2.layers[\"counts\"] = input_train_mod2.X.astype(np.float32)\n",
    "\n",
    "mod1_feature_type = 'GEX'\n",
    "mod2_feature_type = 'ADT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AnnData object with n_obs × n_vars = 14468 × 17009\n",
       "     obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'nCount_ADT', 'nFeature_ADT', 'lane', 'donor', 'celltype.l1', 'celltype.l2', 'RNA.weight', 'batch'\n",
       "     layers: 'counts',\n",
       " AnnData object with n_obs × n_vars = 14468 × 25\n",
       "     obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'nCount_ADT', 'nFeature_ADT', 'lane', 'donor', 'celltype.l1', 'celltype.l2', 'RNA.weight', 'batch'\n",
       "     layers: 'counts')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train_mod1, input_train_mod2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if {mod1_feature_type, mod2_feature_type} == {\"GEX\", \"ATAC\"}:\n",
    "    omics = \"multiome\"\n",
    "elif {mod1_feature_type, mod2_feature_type} == {\"GEX\", \"ADT\"}:\n",
    "    omics = \"cite\"\n",
    "else:\n",
    "    raise RuntimeError(\"Unrecognized modality!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if omics == \"cite\":\n",
    "    n_genes = 5000\n",
    "    latent_dim = 20\n",
    "    x2u_h_depth = 2\n",
    "    x2u_h_dim = 512\n",
    "    u2x_h_depth = 1\n",
    "    u2x_h_dim = 128\n",
    "    du_h_depth = 2\n",
    "    du_h_dim = 128\n",
    "    dropout = 0.2\n",
    "    lam_data = 1.0\n",
    "    lam_kl = 1.0\n",
    "    lam_align = 2.0\n",
    "    lam_cross = 2.0\n",
    "    lam_cos = 1.0\n",
    "    normalize_u = True\n",
    "    random_seed = 5\n",
    "elif omics == \"multiome\":\n",
    "    n_genes = 10000\n",
    "    latent_dim = 50\n",
    "    x2u_h_depth = 2\n",
    "    x2u_h_dim = 512\n",
    "    u2x_h_depth = 1\n",
    "    u2x_h_dim = 256\n",
    "    du_h_depth = 1\n",
    "    du_h_dim = 256\n",
    "    dropout = 0.2\n",
    "    lam_data = 1.0\n",
    "    lam_kl = 0.3\n",
    "    lam_align = 0.02\n",
    "    lam_cross = 1.0\n",
    "    lam_cos = 0.02\n",
    "    normalize_u = True\n",
    "    random_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(par['output_pretrain'], exist_ok=True)\n",
    "with open(os.path.join(par['output_pretrain'], \"hyperparams.yaml\"), \"w\") as f:\n",
    "    yaml.dump({\n",
    "        \"n_genes\": n_genes,\n",
    "        \"latent_dim\": latent_dim,\n",
    "        \"x2u_h_depth\": x2u_h_depth,\n",
    "        \"x2u_h_dim\": x2u_h_dim,\n",
    "        \"u2x_h_depth\": u2x_h_depth,\n",
    "        \"u2x_h_dim\": u2x_h_dim,\n",
    "        \"du_h_depth\": du_h_depth,\n",
    "        \"du_h_dim\": du_h_dim,\n",
    "        \"dropout\": dropout,\n",
    "        \"lam_data\": lam_data,\n",
    "        \"lam_kl\": lam_kl,\n",
    "        \"lam_align\": lam_align,\n",
    "        \"lam_cross\": lam_cross,\n",
    "        \"lam_cos\": lam_cos,\n",
    "        \"normalize_u\": normalize_u,\n",
    "        \"random_seed\": random_seed\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train_mod1.obs[\"uid\"] = [f\"train-{i}\" for i in range(input_train_mod1.shape[0])]\n",
    "input_train_mod2.obs[\"uid\"] = [f\"train-{i}\" for i in range(input_train_mod2.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mod1_feature_type == \"GEX\":\n",
    "    gex = input_train_mod1\n",
    "    other = input_train_mod2\n",
    "else:\n",
    "    gex = input_train_mod2\n",
    "    other = input_train_mod1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing GEX...\n",
      "Preprocessing ADT...\n"
     ]
    }
   ],
   "source": [
    "print('Preprocessing GEX...')\n",
    "gex_prep = utils.GEXPreprocessing(n_comps=100, n_genes=n_genes, merge_adt=omics == \"cite\")\n",
    "gex_prep.fit_transform(gex)\n",
    "\n",
    "if omics == \"cite\":\n",
    "    print('Preprocessing ADT...')\n",
    "    other_prep = utils.ADTPreprocessing(n_comps=100)\n",
    "elif omics == \"multiome\":\n",
    "    print('Preprocessing ATAC...')\n",
    "    other_prep = utils.ATACPreprocessing(n_comps=100)\n",
    "    \n",
    "other_prep.fit_transform(other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(par['output_pretrain'], \"prep.pickle\"), \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"gex_prep\": gex_prep,\n",
    "        \"other_prep\": other_prep\n",
    "    }, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scglue.models.configure_dataset(\n",
    "    gex, \"NB\", use_highly_variable=True,\n",
    "    use_layer=\"counts\", use_rep=\"X_pca\",\n",
    "    use_batch=\"batch\", use_uid=\"uid\"\n",
    ")\n",
    "scglue.models.configure_dataset(\n",
    "    other, \"NB\", use_highly_variable=True,\n",
    "    use_layer=\"counts\", use_rep=\"X_pca\",\n",
    "    use_batch=\"batch\", use_uid=\"uid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "[INFO] autodevice: Using GPU 1 as computation device.\n"
     ]
    }
   ],
   "source": [
    "print('Building model...')\n",
    "model = scglue.models.SCCLUEModel(\n",
    "    {\"gex\": gex, \"other\": other},\n",
    "    latent_dim=latent_dim,\n",
    "    x2u_h_depth=x2u_h_depth,\n",
    "    x2u_h_dim=x2u_h_dim,\n",
    "    u2x_h_depth=u2x_h_depth,\n",
    "    u2x_h_dim=u2x_h_dim,\n",
    "    du_h_depth=du_h_depth,\n",
    "    du_h_dim=du_h_dim,\n",
    "    dropout=dropout,\n",
    "    shared_batches=True,\n",
    "    random_seed=random_seed\n",
    ")\n",
    "\n",
    "training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pretrained weight\n",
    "# model = scglue.models.load_model(os.path.join(par['output_pretrain'], \"pretrain.dill\"))\n",
    "# training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n"
     ]
    }
   ],
   "source": [
    "print('Compiling model...')\n",
    "model.compile(\n",
    "    lam_data=lam_data, lam_kl=lam_kl, lam_align=lam_align,\n",
    "    lam_cross=lam_cross, lam_cos=lam_cos, normalize_u=normalize_u,\n",
    "    domain_weight={\"gex\": 1, \"other\": 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "[INFO] SCCLUEModel: Setting `align_burnin` = 59\n",
      "[INFO] SCCLUEModel: Setting `max_epochs` = 354\n",
      "[INFO] SCCLUEModel: Setting `patience` = 45\n",
      "[INFO] SCCLUEModel: Setting `reduce_lr_patience` = 15\n",
      "[INFO] SCCLUETrainer: Using training directory: \"/tmp/GLUETMPad1ixwsv\"\n",
      "[INFO] SCCLUETrainer: [Epoch 10] train={'dsc_loss': 0.682, 'gen_loss': 15.598, 'cross_loss': 5.423, 'cos_loss': 0.313, 'x_gex_nll': 0.201, 'x_gex_kl': 0.02, 'x_gex_elbo': 0.221, 'x_other_nll': 5.257, 'x_other_kl': 0.325, 'x_other_elbo': 5.582}, val={'dsc_loss': 0.685, 'gen_loss': 15.471, 'cross_loss': 5.384, 'cos_loss': 0.305, 'x_gex_nll': 0.2, 'x_gex_kl': 0.019, 'x_gex_elbo': 0.219, 'x_other_nll': 5.221, 'x_other_kl': 0.327, 'x_other_elbo': 5.548}, 3.5s elapsed\n",
      "[INFO] SCCLUETrainer: [Epoch 20] train={'dsc_loss': 0.675, 'gen_loss': 13.388, 'cross_loss': 4.653, 'cos_loss': 0.282, 'x_gex_nll': 0.184, 'x_gex_kl': 0.019, 'x_gex_elbo': 0.203, 'x_other_nll': 4.485, 'x_other_kl': 0.462, 'x_other_elbo': 4.947}, val={'dsc_loss': 0.673, 'gen_loss': 13.39, 'cross_loss': 4.626, 'cos_loss': 0.277, 'x_gex_nll': 0.185, 'x_gex_kl': 0.018, 'x_gex_elbo': 0.203, 'x_other_nll': 4.537, 'x_other_kl': 0.467, 'x_other_elbo': 5.005}, 3.4s elapsed\n",
      "[INFO] SCCLUETrainer: [Epoch 30] train={'dsc_loss': 0.67, 'gen_loss': 13.133, 'cross_loss': 4.548, 'cos_loss': 0.268, 'x_gex_nll': 0.182, 'x_gex_kl': 0.018, 'x_gex_elbo': 0.2, 'x_other_nll': 4.375, 'x_other_kl': 0.535, 'x_other_elbo': 4.91}, val={'dsc_loss': 0.674, 'gen_loss': 13.219, 'cross_loss': 4.566, 'cos_loss': 0.269, 'x_gex_nll': 0.181, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.199, 'x_other_nll': 4.451, 'x_other_kl': 0.518, 'x_other_elbo': 4.969}, 3.5s elapsed\n",
      "[INFO] SCCLUETrainer: [Epoch 40] train={'dsc_loss': 0.676, 'gen_loss': 13.058, 'cross_loss': 4.526, 'cos_loss': 0.265, 'x_gex_nll': 0.181, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.198, 'x_other_nll': 4.348, 'x_other_kl': 0.548, 'x_other_elbo': 4.896}, val={'dsc_loss': 0.678, 'gen_loss': 13.164, 'cross_loss': 4.548, 'cos_loss': 0.266, 'x_gex_nll': 0.183, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.2, 'x_other_nll': 4.426, 'x_other_kl': 0.532, 'x_other_elbo': 4.958}, 3.0s elapsed\n",
      "[INFO] SCCLUETrainer: [Epoch 50] train={'dsc_loss': 0.676, 'gen_loss': 13.031, 'cross_loss': 4.517, 'cos_loss': 0.265, 'x_gex_nll': 0.18, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.197, 'x_other_nll': 4.34, 'x_other_kl': 0.547, 'x_other_elbo': 4.888}, val={'dsc_loss': 0.669, 'gen_loss': 13.119, 'cross_loss': 4.523, 'cos_loss': 0.261, 'x_gex_nll': 0.182, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.199, 'x_other_nll': 4.411, 'x_other_kl': 0.541, 'x_other_elbo': 4.952}, 3.5s elapsed\n",
      "[INFO] SCCLUETrainer: [Epoch 60] train={'dsc_loss': 0.679, 'gen_loss': 12.996, 'cross_loss': 4.504, 'cos_loss': 0.264, 'x_gex_nll': 0.181, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.198, 'x_other_nll': 4.333, 'x_other_kl': 0.551, 'x_other_elbo': 4.884}, val={'dsc_loss': 0.675, 'gen_loss': 13.154, 'cross_loss': 4.548, 'cos_loss': 0.266, 'x_gex_nll': 0.182, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.2, 'x_other_nll': 4.41, 'x_other_kl': 0.533, 'x_other_elbo': 4.942}, 4.7s elapsed\n",
      "[INFO] SCCLUETrainer: [Epoch 70] train={'dsc_loss': 0.678, 'gen_loss': 12.987, 'cross_loss': 4.499, 'cos_loss': 0.263, 'x_gex_nll': 0.18, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.197, 'x_other_nll': 4.329, 'x_other_kl': 0.556, 'x_other_elbo': 4.884}, val={'dsc_loss': 0.673, 'gen_loss': 13.167, 'cross_loss': 4.551, 'cos_loss': 0.271, 'x_gex_nll': 0.184, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.201, 'x_other_nll': 4.4, 'x_other_kl': 0.54, 'x_other_elbo': 4.94}, 4.0s elapsed\n",
      "[INFO] SCCLUETrainer: [Epoch 80] train={'dsc_loss': 0.68, 'gen_loss': 12.959, 'cross_loss': 4.489, 'cos_loss': 0.264, 'x_gex_nll': 0.18, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.197, 'x_other_nll': 4.32, 'x_other_kl': 0.56, 'x_other_elbo': 4.88}, val={'dsc_loss': 0.676, 'gen_loss': 13.133, 'cross_loss': 4.55, 'cos_loss': 0.273, 'x_gex_nll': 0.181, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.198, 'x_other_nll': 4.372, 'x_other_kl': 0.541, 'x_other_elbo': 4.913}, 3.5s elapsed\n",
      "Epoch 00084: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 00084: reducing learning rate of group 0 to 2.0000e-04.\n",
      "[INFO] SCCLUETrainer: [Epoch 90] train={'dsc_loss': 0.685, 'gen_loss': 12.875, 'cross_loss': 4.466, 'cos_loss': 0.26, 'x_gex_nll': 0.18, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.197, 'x_other_nll': 4.302, 'x_other_kl': 0.554, 'x_other_elbo': 4.855}, val={'dsc_loss': 0.667, 'gen_loss': 13.123, 'cross_loss': 4.538, 'cos_loss': 0.266, 'x_gex_nll': 0.181, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.198, 'x_other_nll': 4.37, 'x_other_kl': 0.548, 'x_other_elbo': 4.918}, 3.9s elapsed\n",
      "[INFO] SCCLUETrainer: [Epoch 100] train={'dsc_loss': 0.683, 'gen_loss': 12.864, 'cross_loss': 4.458, 'cos_loss': 0.259, 'x_gex_nll': 0.18, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.197, 'x_other_nll': 4.295, 'x_other_kl': 0.563, 'x_other_elbo': 4.858}, val={'dsc_loss': 0.669, 'gen_loss': 13.11, 'cross_loss': 4.538, 'cos_loss': 0.267, 'x_gex_nll': 0.182, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.199, 'x_other_nll': 4.352, 'x_other_kl': 0.553, 'x_other_elbo': 4.905}, 3.4s elapsed\n",
      "Epoch 00108: reducing learning rate of group 0 to 2.0000e-05.\n",
      "Epoch 00108: reducing learning rate of group 0 to 2.0000e-05.\n",
      "[INFO] SCCLUETrainer: [Epoch 110] train={'dsc_loss': 0.684, 'gen_loss': 12.865, 'cross_loss': 4.458, 'cos_loss': 0.26, 'x_gex_nll': 0.18, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.197, 'x_other_nll': 4.293, 'x_other_kl': 0.568, 'x_other_elbo': 4.861}, val={'dsc_loss': 0.668, 'gen_loss': 13.129, 'cross_loss': 4.543, 'cos_loss': 0.269, 'x_gex_nll': 0.181, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.198, 'x_other_nll': 4.358, 'x_other_kl': 0.554, 'x_other_elbo': 4.912}, 3.6s elapsed\n",
      "[INFO] SCCLUETrainer: [Epoch 120] train={'dsc_loss': 0.684, 'gen_loss': 12.843, 'cross_loss': 4.451, 'cos_loss': 0.258, 'x_gex_nll': 0.18, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.197, 'x_other_nll': 4.287, 'x_other_kl': 0.567, 'x_other_elbo': 4.855}, val={'dsc_loss': 0.668, 'gen_loss': 13.131, 'cross_loss': 4.542, 'cos_loss': 0.269, 'x_gex_nll': 0.182, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.199, 'x_other_nll': 4.366, 'x_other_kl': 0.55, 'x_other_elbo': 4.916}, 3.4s elapsed\n",
      "[INFO] SCCLUETrainer: [Epoch 130] train={'dsc_loss': 0.685, 'gen_loss': 12.862, 'cross_loss': 4.457, 'cos_loss': 0.259, 'x_gex_nll': 0.18, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.197, 'x_other_nll': 4.294, 'x_other_kl': 0.568, 'x_other_elbo': 4.862}, val={'dsc_loss': 0.669, 'gen_loss': 13.159, 'cross_loss': 4.563, 'cos_loss': 0.27, 'x_gex_nll': 0.18, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.198, 'x_other_nll': 4.352, 'x_other_kl': 0.551, 'x_other_elbo': 4.903}, 3.5s elapsed\n",
      "Epoch 00132: reducing learning rate of group 0 to 2.0000e-06.\n",
      "Epoch 00132: reducing learning rate of group 0 to 2.0000e-06.\n",
      "[INFO] SCCLUETrainer: [Epoch 140] train={'dsc_loss': 0.685, 'gen_loss': 12.853, 'cross_loss': 4.455, 'cos_loss': 0.258, 'x_gex_nll': 0.18, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.197, 'x_other_nll': 4.29, 'x_other_kl': 0.567, 'x_other_elbo': 4.858}, val={'dsc_loss': 0.669, 'gen_loss': 13.14, 'cross_loss': 4.547, 'cos_loss': 0.266, 'x_gex_nll': 0.181, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.198, 'x_other_nll': 4.363, 'x_other_kl': 0.554, 'x_other_elbo': 4.918}, 3.8s elapsed\n",
      "Epoch 00148: reducing learning rate of group 0 to 2.0000e-07.\n",
      "Epoch 00148: reducing learning rate of group 0 to 2.0000e-07.\n",
      "[INFO] SCCLUETrainer: [Epoch 150] train={'dsc_loss': 0.685, 'gen_loss': 12.849, 'cross_loss': 4.453, 'cos_loss': 0.259, 'x_gex_nll': 0.18, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.197, 'x_other_nll': 4.289, 'x_other_kl': 0.568, 'x_other_elbo': 4.857}, val={'dsc_loss': 0.669, 'gen_loss': 13.137, 'cross_loss': 4.543, 'cos_loss': 0.267, 'x_gex_nll': 0.182, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.199, 'x_other_nll': 4.363, 'x_other_kl': 0.56, 'x_other_elbo': 4.923}, 3.8s elapsed\n",
      "[INFO] SCCLUETrainer: [Epoch 160] train={'dsc_loss': 0.686, 'gen_loss': 12.858, 'cross_loss': 4.456, 'cos_loss': 0.259, 'x_gex_nll': 0.18, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.197, 'x_other_nll': 4.294, 'x_other_kl': 0.568, 'x_other_elbo': 4.862}, val={'dsc_loss': 0.669, 'gen_loss': 13.123, 'cross_loss': 4.54, 'cos_loss': 0.268, 'x_gex_nll': 0.18, 'x_gex_kl': 0.017, 'x_gex_elbo': 0.197, 'x_other_nll': 4.365, 'x_other_kl': 0.55, 'x_other_elbo': 4.915}, 3.4s elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 18:13:23,597 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EarlyStopping: Restoring checkpoint \"126\"...\n",
      "[INFO] EarlyStopping: Restoring checkpoint \"126\"...\n"
     ]
    }
   ],
   "source": [
    "if training:\n",
    "    print('Training model...')\n",
    "    model.fit(\n",
    "        {\"gex\": gex, \"other\": other}\n",
    "    )\n",
    "    model.save(os.path.join(par['output_pretrain'], \"pretrain.dill\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch112",
   "language": "python",
   "name": "torch112"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
