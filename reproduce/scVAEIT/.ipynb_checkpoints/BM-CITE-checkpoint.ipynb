{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BM-CITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"11\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"8\" # export OPENBLAS_NUM_THREADS=4 \n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"11\" # export MKL_NUM_THREADS=6\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"8\" # export VECLIB_MAXIMUM_THREADS=4\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"11\" # export NUMEXPR_NUM_THREADS=6\n",
    "os.environ[\"NUMBA_CACHE_DIR\"]='/tmp/numba_cache'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy \n",
    "import scipy.io as sio\n",
    "import scipy.sparse as sps\n",
    "import h5py\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "\n",
    "from os.path import join\n",
    "import sys\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# try:\n",
    "#     tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "# except:\n",
    "#     # Invalid device or cannot modify virtual devices once initialized.\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import copy\n",
    "import gc\n",
    "def pearson_mat(X0, Y0):\n",
    "    X, Y = copy.deepcopy(X0), copy.deepcopy(Y0)\n",
    "    X = (X - X.mean(axis=0))\n",
    "    X /= (scipy.linalg.norm(X, axis=0, ord=2) + 1e-12)\n",
    "    Y = (Y - Y.mean(axis=0))\n",
    "    Y /= (scipy.linalg.norm(Y, axis=0, ord=2) + 1e-12)\n",
    "    res = (X * Y).sum(axis=0)\n",
    "    del X, Y\n",
    "    gc.collect()\n",
    "    return res\n",
    "\n",
    "def pearson_mat_axis1(X0, Y0):\n",
    "    X, Y = copy.deepcopy(X0), copy.deepcopy(Y0)\n",
    "    X = (X - X.mean(axis=1, keepdims=True))\n",
    "    X /= (scipy.linalg.norm(X, axis=1, ord=2, keepdims=True) + 1e-12)\n",
    "    Y = (Y - Y.mean(axis=1, keepdims=True))\n",
    "    Y /= (scipy.linalg.norm(Y, axis=1, ord=2, keepdims=True) + 1e-12)\n",
    "    res = (X * Y).sum(axis=1)\n",
    "    del X, Y\n",
    "    gc.collect()\n",
    "    return res\n",
    "\n",
    "def eval_PearSpear_AlongGene(X, Y):\n",
    "    pears = pearson_mat(X, Y)\n",
    "    spears = []\n",
    "    for gi in range(X.shape[1]):\n",
    "        spears.append(scipy.stats.spearmanr(X[:, gi], Y[:, gi])[0])\n",
    "    return pears, spears\n",
    "\n",
    "def eval_PearSpear_AlongCell(X, Y):\n",
    "    pear_alongcell = pearson_mat_axis1(X, Y)\n",
    "    spear_alongcell = []\n",
    "    for ci in range(X.shape[0]):\n",
    "        spear_alongcell.append(scipy.stats.spearmanr(X[ci, ], Y[ci, ])[0])\n",
    "    return pear_alongcell, spear_alongcell\n",
    "        \n",
    "def eval_imputation_flatten(x, y):\n",
    "    pearson_r, pearson_p = scipy.stats.pearsonr(x, y)\n",
    "    print(f\"Found pearson's correlation/p of {pearson_r:.4f}/{pearson_p:.4g}\")\n",
    "    spearman_corr, spearman_p = scipy.stats.spearmanr(x, y)\n",
    "    print(f\"Found spearman's collelation/p of {spearman_corr:.4f}/{spearman_p:.4g}\")\n",
    "    rmse = np.sqrt(np.mean((x - y)**2))\n",
    "    print(f\"Found rmse {rmse:.4f}\")\n",
    "    return pearson_r, spearman_corr, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9340/843584074.py:14: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  ad_rna = sc.AnnData(X, obs=meta_data.loc[cell_names])\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/home/yanxh/data/Seurat_demo_data/bm_cite\"\n",
    "\n",
    "X = sps.csr_matrix(sio.mmread(join(data_dir, 'rna_mat_norm.mtx')).T)\n",
    "Y = sps.csr_matrix(sio.mmread(join(data_dir, 'adt_mat_norm.mtx')).T)\n",
    "\n",
    "rna_names = pd.read_csv(join(data_dir, 'gene_names.csv'))['x'].to_numpy()\n",
    "adt_names = pd.read_csv(join(data_dir, 'adt_names.csv'))['x'].to_numpy()\n",
    "\n",
    "cell_names = pd.read_csv(join(data_dir, 'cell_names.csv'))['x'].to_numpy()\n",
    "meta_data = pd.read_csv(join(data_dir, 'metadata.csv'), index_col=0)\n",
    "meta_data['batch'] = meta_data['donor'].to_numpy()\n",
    "\n",
    "# select hvg\n",
    "ad_rna = sc.AnnData(X, obs=meta_data.loc[cell_names])\n",
    "sc.pp.highly_variable_genes(ad_rna, n_top_genes=5000)\n",
    "hvg_idx = np.where(ad_rna.var.highly_variable)[0]\n",
    "\n",
    "train_idx = np.where((meta_data.batch=='batch1').to_numpy())[0]\n",
    "test_idx  = np.where((meta_data.batch=='batch2').to_numpy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_X = X[train_idx][:, hvg_idx].A\n",
    "mult_Y = Y[train_idx].A\n",
    "single_X  = X[test_idx][:, hvg_idx].A\n",
    "single_Y  = Y[test_idx].A\n",
    "\n",
    "n_mult, n_rna, n_adt = mult_X.shape[0], single_X.shape[0], single_Y.shape[0]\n",
    "m_rna, m_adt = mult_X.shape[1], mult_Y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_data = np.hstack([mult_X, mult_Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_input_arr = [m_rna, m_adt]\n",
    "config = {\n",
    "    'dim_input_arr': dim_input_arr,\n",
    "    'dimensions':[256], \n",
    "    'dim_latent':32,\n",
    "    'dim_block': np.array(dim_input_arr),\n",
    "    'dist_block':['NB','NB'], \n",
    "    'dim_block_enc':np.array([256, 128]),\n",
    "    'dim_block_dec':np.array([256, 128]),\n",
    "    'dim_block_embed':np.array([32, 16]),\n",
    "    \n",
    "    'block_names':np.array(['rna', 'adt']),\n",
    "    'uni_block_names':np.array(['rna','adt']),\n",
    "    \n",
    "    'beta_kl':1.,\n",
    "    'beta_unobs':2./3.,\n",
    "    'beta_modal':np.array([0.15,0.85]),\n",
    "    'beta_reverse':0.5,\n",
    "\n",
    "    \"p_feat\" : 0.2,\n",
    "    \"p_modal\" : np.ones(2)/2,\n",
    "    \n",
    "}\n",
    "config = SimpleNamespace(**config)\n",
    "n_samples = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-01 18:07:26.388309: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-01 18:07:26.806834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22306 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:b3:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from scVAEIT.VAEIT import scVAEIT\n",
    "# model = scVAEIT(config, mosaic_data, masks, batch_ids)  # for integration\n",
    "model = scVAEIT(config, mult_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    model.train(\n",
    "        valid=False, num_epoch=500, batch_size=512, save_every_epoch=50,\n",
    "        verbose=True, checkpoint_dir='./checkpoint/bm-cite-impute'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We skip the training process here and load the model checkpoint directly.\n",
    "\n",
    "```\n",
    "model.train(\n",
    "        valid=False, num_epoch=500, batch_size=512, save_every_epoch=50,\n",
    "        verbose=True, checkpoint_dir=path_root+'checkpoint/')\n",
    "```        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
      "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
      "<tensorflow.python.training.tracking.util.CheckpointLoadStatus object at 0x7f8b25cc3880>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-01 18:07:29.263446: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "# load the model and ensure it is loaded successfully\n",
    "checkpoint = tf.train.Checkpoint(net=model.vae)\n",
    "epoch = 10\n",
    "status = checkpoint.restore('checkpoint/bm-cite-impute/ckpt-{}'.format(epoch))\n",
    "\n",
    "# one-step forward?\n",
    "model.vae(tf.zeros((1,np.sum(model.vae.config.dim_input_arr))),\n",
    "          tf.zeros((1,np.sum(model.vae.config.dim_input_arr))),\n",
    "          tf.zeros((1,np.sum(model.batches.shape[1]))), \n",
    "          pre_train=True, L=1, training=False)\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = tf.data.Dataset.from_tensor_slices((\n",
    "    np.hstack([single_X, single_Y]),\n",
    "    model.cat_enc.transform(np.zeros((test_idx.size, 1))).toarray().astype(np.float32),\n",
    "    np.zeros(test_idx.size).astype(np.int32)\n",
    ")).batch(512).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# adt->rna\n",
    "mask_rna = np.zeros((1, m_rna+m_adt), dtype=np.float32)\n",
    "mask_rna[:,:m_rna] = -1.\n",
    "recon = model.vae.get_recon(dataset_test, mask_rna)\n",
    "X_hat = recon[:, :m_rna]\n",
    "\n",
    "mask_adt = np.zeros((1, m_rna+m_adt), dtype=np.float32)\n",
    "mask_adt[:, m_rna:] = -1.\n",
    "recon = model.vae.get_recon(dataset_test, mask_adt)\n",
    "Y_hat = recon[:, m_rna:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pearson's correlation/p of 0.9455/0\n",
      "Found spearman's collelation/p of 0.9220/0\n",
      "Found rmse 0.3309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8338684714571624,\n",
       " 0.6725610199600964,\n",
       " 0.9473096467951613,\n",
       " 0.9163671292480389)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch2: rna->adt\n",
    "pear1, spear1, rmse = eval_imputation_flatten(single_Y.flatten(), Y_hat.flatten())\n",
    "pear_along_adt, spear_along_adt = eval_PearSpear_AlongGene(single_Y, Y_hat)\n",
    "adt_pear_along_cell, adt_spear_along_cell = eval_PearSpear_AlongCell(single_Y, Y_hat)\n",
    "\n",
    "np.mean(pear_along_adt), np.mean(spear_along_adt), np.mean(adt_pear_along_cell), np.mean(adt_spear_along_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pearson's correlation/p of 0.7605/0\n",
      "Found spearman's collelation/p of 0.2626/0\n",
      "Found rmse 0.2658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1285874402664802, nan, 0.764599843625379, 0.2548823767857744)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch3: adt->rna\n",
    "pear1, spear1, rmse = eval_imputation_flatten(single_X.flatten(), X_hat.flatten())\n",
    "pear_along_gene, spear_along_gene = eval_PearSpear_AlongGene(single_X, X_hat)\n",
    "gene_pear_along_cell, gene_spear_along_cell = eval_PearSpear_AlongCell(single_X, X_hat)\n",
    "\n",
    "np.mean(pear_along_gene), np.mean(spear_along_gene), np.mean(gene_pear_along_cell), np.mean(gene_spear_along_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/home/yanxh/gitrepo/multi-omics-matching/Visualization/outputs/imputation'\n",
    "\n",
    "adt_metcs = np.vstack([pear_along_adt, spear_along_adt]).T\n",
    "_df1 = pd.DataFrame(adt_metcs, index=adt_names, columns=['pear', 'spear'])\n",
    "_df1.to_csv(join(save_dir, 'scVAEIT_bm-cite_along_adt.csv'))\n",
    "\n",
    "gene_metcs = np.vstack([pear_along_gene, spear_along_gene]).T\n",
    "_df2 = pd.DataFrame(gene_metcs, index=rna_names[hvg_idx], columns=['pear', 'spear'])\n",
    "_df2.to_csv(join(save_dir, 'scVAEIT_bm-cite_along_gene.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/home/yanxh/gitrepo/multi-omics-matching/Visualization/outputs/imputation'\n",
    "\n",
    "_metcs = np.vstack([adt_pear_along_cell, adt_spear_along_cell, gene_pear_along_cell, gene_spear_along_cell]).T\n",
    "_df1 = pd.DataFrame(_metcs, index=cell_names[test_idx], columns=['adt_pear', 'adt_spear', 'gene_pear', 'gene_spear'])\n",
    "_df1.to_csv(join(save_dir, 'scVAEIT_bm-cite_along_cell.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./checkpoint/bm-cite-impute/X_test_imputed.npy', X_hat)\n",
    "np.save('./checkpoint/bm-cite-impute/Y_test_imputed.npy', Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-py38",
   "language": "python",
   "name": "tf2-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
